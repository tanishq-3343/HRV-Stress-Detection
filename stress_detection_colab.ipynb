{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéôÔ∏è Voice-Based Stress Detection Using MFCC + Time-Series Features\n",
    "### Case Study ‚Äî Signal Processing & Machine Learning\n",
    "\n",
    "This notebook walks through the complete pipeline:\n",
    "1. Data Setup & Synthetic Generation\n",
    "2. Signal Preprocessing\n",
    "3. Feature Extraction (MFCC, ZCR, Spectral Centroid, Energy, Pitch)\n",
    "4. Time-Series Analysis\n",
    "5. Machine Learning Classification\n",
    "6. Evaluation & Visualization\n",
    "\n",
    "---\n",
    "> **Dataset options:** [RAVDESS](https://zenodo.org/record/1188976), [EmoDB](http://emodb.bilderbar.info/), [IITKGP Stress Speech Corpus](https://www.slt.ii.ets.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Section 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa soundfile scikit-learn matplotlib seaborn pandas numpy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import os\n",
    "import warnings\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plot style\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 120,\n",
    "    'axes.titlesize': 13,\n",
    "    'axes.labelsize': 11,\n",
    "    'font.family': 'DejaVu Sans'\n",
    "})\n",
    "sns.set_theme(style='whitegrid', palette='muted')\n",
    "\n",
    "print('‚úÖ All libraries loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéß Section 2: Data Setup\n",
    "\n",
    "### Option A ‚Äî Use Your Own Dataset (RAVDESS / EmoDB / IITKGP)\n",
    "Upload audio files and update the paths below.\n",
    "\n",
    "### Option B ‚Äî Synthetic Data (default, runs immediately)\n",
    "We synthesize 200 realistic speech-like signals ‚Äî 100 normal, 100 stressed ‚Äî to demonstrate the full pipeline without needing external files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# OPTION A: Real Dataset\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Uncomment and set paths below if using real audio files:\n",
    "#\n",
    "# DATASET_DIR = '/content/drive/MyDrive/stress_dataset'\n",
    "# NORMAL_DIR  = os.path.join(DATASET_DIR, 'normal')\n",
    "# STRESSED_DIR = os.path.join(DATASET_DIR, 'stressed')\n",
    "#\n",
    "# audio_files = []\n",
    "# for f in os.listdir(NORMAL_DIR):\n",
    "#     if f.endswith('.wav'): audio_files.append((os.path.join(NORMAL_DIR, f), 'normal'))\n",
    "# for f in os.listdir(STRESSED_DIR):\n",
    "#     if f.endswith('.wav'): audio_files.append((os.path.join(STRESSED_DIR, f), 'stressed'))\n",
    "#\n",
    "# USE_SYNTHETIC = False\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# OPTION B: Synthetic Data  ‚Üê runs by default\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "USE_SYNTHETIC = True\n",
    "SR = 22050        # sample rate\n",
    "DURATION = 3.0    # seconds per sample\n",
    "N_SAMPLES = 200   # total (100 normal + 100 stressed)\n",
    "SYNTHETIC_DIR = '/content/synthetic_audio'\n",
    "os.makedirs(SYNTHETIC_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def synthesize_speech(label, idx, sr=SR, duration=DURATION):\n",
    "    \"\"\"Generate a speech-like signal with label-specific characteristics.\"\"\"\n",
    "    t = np.linspace(0, duration, int(sr * duration))\n",
    "    rng = np.random.default_rng(idx)\n",
    "\n",
    "    if label == 'normal':\n",
    "        # Steady fundamental + harmonics, low jitter\n",
    "        f0 = rng.uniform(120, 200)                     # fundamental Hz\n",
    "        jitter = 0.002                                  # small pitch jitter\n",
    "        energy_mod = 0.3                                # stable amplitude\n",
    "        noise_level = 0.03\n",
    "    else:\n",
    "        # Higher-pitched, more jitter, more energy modulation, more noise\n",
    "        f0 = rng.uniform(180, 280)\n",
    "        jitter = 0.015\n",
    "        energy_mod = 0.7\n",
    "        noise_level = 0.12\n",
    "\n",
    "    # Build signal: fundamental + harmonics with jitter\n",
    "    freq = f0 * (1 + jitter * rng.standard_normal(len(t)))\n",
    "    phase = np.cumsum(2 * np.pi * freq / sr)\n",
    "    signal = np.sin(phase)\n",
    "    signal += 0.5 * np.sin(2 * phase)\n",
    "    signal += 0.25 * np.sin(3 * phase)\n",
    "\n",
    "    # Amplitude envelope\n",
    "    envelope = 1 + energy_mod * np.sin(2 * np.pi * 3 * t + rng.uniform(0, 2 * np.pi))\n",
    "    signal = signal * envelope\n",
    "\n",
    "    # Add broadband noise\n",
    "    signal += noise_level * rng.standard_normal(len(t))\n",
    "\n",
    "    # Normalize\n",
    "    signal = signal / (np.max(np.abs(signal)) + 1e-8)\n",
    "    signal = signal.astype(np.float32)\n",
    "\n",
    "    path = os.path.join(SYNTHETIC_DIR, f'{label}_{idx:03d}.wav')\n",
    "    sf.write(path, signal, sr)\n",
    "    return path\n",
    "\n",
    "\n",
    "audio_files = []\n",
    "for i in range(N_SAMPLES // 2):\n",
    "    audio_files.append((synthesize_speech('normal',  i),           'normal'))\n",
    "    audio_files.append((synthesize_speech('stressed', i + 1000),   'stressed'))\n",
    "\n",
    "print(f'‚úÖ {len(audio_files)} audio files ready ({N_SAMPLES//2} normal, {N_SAMPLES//2} stressed)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Section 3: Signal Preprocessing & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(path, sr=SR):\n",
    "    y, _ = librosa.load(path, sr=sr)\n",
    "    return y\n",
    "\n",
    "\n",
    "# Pick representative samples\n",
    "normal_sample_path  = [p for p, l in audio_files if l == 'normal'][0]\n",
    "stressed_sample_path = [p for p, l in audio_files if l == 'stressed'][0]\n",
    "\n",
    "y_normal  = load_audio(normal_sample_path)\n",
    "y_stressed = load_audio(stressed_sample_path)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 5), sharex=True)\n",
    "\n",
    "for ax, y, label, color in zip(\n",
    "    axes,\n",
    "    [y_normal, y_stressed],\n",
    "    ['Normal Speech', 'Stressed Speech'],\n",
    "    ['steelblue', 'tomato']\n",
    "):\n",
    "    times = np.linspace(0, DURATION, len(y))\n",
    "    ax.plot(times, y, color=color, linewidth=0.6, alpha=0.85)\n",
    "    ax.set_title(f'Waveform ‚Äî {label}', fontweight='bold')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.set_ylim(-1.1, 1.1)\n",
    "\n",
    "axes[-1].set_xlabel('Time (s)')\n",
    "plt.suptitle('üìà Waveform Comparison', fontsize=14, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/plot_waveforms.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "print('Waveform plot saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Spectrogram Comparison ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, y, label in zip(axes, [y_normal, y_stressed], ['Normal', 'Stressed']):\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, sr=SR, x_axis='time', y_axis='hz', ax=ax, cmap='magma')\n",
    "    ax.set_title(f'Spectrogram ‚Äî {label}', fontweight='bold')\n",
    "    ax.set_ylim(0, 4000)\n",
    "    plt.colorbar(img, ax=ax, format='%+2.0f dB', shrink=0.8)\n",
    "\n",
    "plt.suptitle('üîä Spectrograms', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/plot_spectrograms.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "print('Spectrogram plot saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßÆ Section 4: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(y, sr=SR, n_mfcc=13):\n",
    "    \"\"\"Extract comprehensive feature set from a speech signal.\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    # ‚îÄ‚îÄ MFCC (13 coefficients) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    for i in range(n_mfcc):\n",
    "        features[f'mfcc_{i+1}_mean'] = np.mean(mfcc[i])\n",
    "        features[f'mfcc_{i+1}_std']  = np.std(mfcc[i])\n",
    "\n",
    "    # Delta MFCCs (velocity)\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)\n",
    "    for i in range(n_mfcc):\n",
    "        features[f'mfcc_delta_{i+1}_mean'] = np.mean(mfcc_delta[i])\n",
    "\n",
    "    # ‚îÄ‚îÄ Zero Crossing Rate ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    features['zcr_mean'] = np.mean(zcr)\n",
    "    features['zcr_std']  = np.std(zcr)\n",
    "\n",
    "    # ‚îÄ‚îÄ Spectral Features ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    sc = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    features['spectral_centroid_mean'] = np.mean(sc)\n",
    "    features['spectral_centroid_std']  = np.std(sc)\n",
    "\n",
    "    sb = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    features['spectral_bandwidth_mean'] = np.mean(sb)\n",
    "\n",
    "    sr_feat = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    features['spectral_rolloff_mean'] = np.mean(sr_feat)\n",
    "\n",
    "    # ‚îÄ‚îÄ RMS Energy ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    features['rms_mean'] = np.mean(rms)\n",
    "    features['rms_std']  = np.std(rms)\n",
    "\n",
    "    # ‚îÄ‚îÄ Pitch (F0) via autocorrelation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    f0, voiced_flag, _ = librosa.pyin(\n",
    "        y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7')\n",
    "    )\n",
    "    f0_voiced = f0[voiced_flag]\n",
    "    features['pitch_mean']    = np.nanmean(f0_voiced) if len(f0_voiced) > 0 else 0\n",
    "    features['pitch_std']     = np.nanstd(f0_voiced)  if len(f0_voiced) > 0 else 0\n",
    "    features['voiced_ratio']  = np.mean(voiced_flag)\n",
    "\n",
    "    # ‚îÄ‚îÄ Chroma ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    features['chroma_mean'] = np.mean(chroma)\n",
    "    features['chroma_std']  = np.std(chroma)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "print('‚è≥ Extracting features from all samples (this may take ~1-2 min)...')\n",
    "\n",
    "records = []\n",
    "for i, (path, label) in enumerate(audio_files):\n",
    "    y = load_audio(path)\n",
    "    feats = extract_features(y)\n",
    "    feats['label'] = label\n",
    "    records.append(feats)\n",
    "    if (i + 1) % 40 == 0:\n",
    "        print(f'  Processed {i+1}/{len(audio_files)} files...')\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print(f'\\n‚úÖ Feature DataFrame shape: {df.shape}')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìâ Section 5: MFCC Trajectory (Time-Series Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "for row, (y, label) in enumerate([(y_normal, 'Normal'), (y_stressed, 'Stressed')]):\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=SR, n_mfcc=13)\n",
    "    frames = np.arange(mfcc.shape[1])\n",
    "\n",
    "    # Plot MFCC heatmap\n",
    "    ax = axes[row, 0]\n",
    "    img = librosa.display.specshow(mfcc, x_axis='frames', ax=ax, cmap='coolwarm')\n",
    "    ax.set_title(f'MFCC Heatmap ‚Äî {label}', fontweight='bold')\n",
    "    ax.set_ylabel('MFCC Coefficient')\n",
    "    plt.colorbar(img, ax=ax, shrink=0.9)\n",
    "\n",
    "    # Plot first 5 MFCC coefficients over time\n",
    "    ax2 = axes[row, 1]\n",
    "    colors = plt.cm.tab10(np.linspace(0, 0.5, 5))\n",
    "    for k, c in zip(range(5), colors):\n",
    "        ax2.plot(frames, mfcc[k], color=c, alpha=0.8, linewidth=0.8, label=f'MFCC {k+1}')\n",
    "    ax2.set_title(f'MFCC Trajectories (1-5) ‚Äî {label}', fontweight='bold')\n",
    "    ax2.set_xlabel('Frame')\n",
    "    ax2.set_ylabel('Coefficient Value')\n",
    "    ax2.legend(loc='upper right', fontsize=8, ncol=2)\n",
    "\n",
    "plt.suptitle('üåä MFCC Time-Series Analysis', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/plot_mfcc_trajectories.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "print('MFCC trajectory plot saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance analysis ‚Äî stressed vs normal MFCCs\n",
    "mfcc_normal   = librosa.feature.mfcc(y=y_normal,   sr=SR, n_mfcc=13)\n",
    "mfcc_stressed = librosa.feature.mfcc(y=y_stressed, sr=SR, n_mfcc=13)\n",
    "\n",
    "var_normal   = np.var(mfcc_normal,   axis=1)\n",
    "var_stressed = np.var(mfcc_stressed, axis=1)\n",
    "\n",
    "x = np.arange(1, 14)\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.bar(x - width/2, var_normal,   width, label='Normal',   color='steelblue', alpha=0.8)\n",
    "ax.bar(x + width/2, var_stressed, width, label='Stressed', color='tomato',    alpha=0.8)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'MFCC {i}' for i in x], rotation=30, ha='right')\n",
    "ax.set_ylabel('Variance')\n",
    "ax.set_title('MFCC Variance ‚Äî Normal vs Stressed', fontweight='bold')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/plot_mfcc_variance.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Section 6: Feature Comparison ‚Äî Normal vs Stressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_features = [\n",
    "    'mfcc_1_mean', 'mfcc_2_mean', 'mfcc_3_mean',\n",
    "    'zcr_mean', 'spectral_centroid_mean', 'rms_mean',\n",
    "    'pitch_mean', 'pitch_std', 'voiced_ratio'\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(13, 11))\n",
    "axes = axes.flatten()\n",
    "\n",
    "palette = {'normal': 'steelblue', 'stressed': 'tomato'}\n",
    "\n",
    "for i, feat in enumerate(compare_features):\n",
    "    ax = axes[i]\n",
    "    for label, color in palette.items():\n",
    "        data = df[df['label'] == label][feat].dropna()\n",
    "        ax.hist(data, bins=18, alpha=0.65, color=color, label=label.capitalize(), edgecolor='white', linewidth=0.5)\n",
    "    ax.set_title(feat.replace('_', ' ').title(), fontweight='bold', fontsize=10)\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle('üìä Feature Distributions: Normal vs Stressed', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/plot_feature_comparison.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "print('Feature comparison plot saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary table\n",
    "summary = df.groupby('label')[compare_features].agg(['mean', 'std']).T\n",
    "summary.columns = ['_'.join(c) for c in summary.columns]\n",
    "print('Feature Statistics by Class:')\n",
    "print(summary.round(4).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Section 7: Machine Learning Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in df.columns if c != 'label']\n",
    "X = df[feature_cols].fillna(0).values\n",
    "y_enc = LabelEncoder().fit_transform(df['label'])   # 0=normal, 1=stressed\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_enc, test_size=0.25, stratify=y_enc, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "classifiers = {\n",
    "    'SVM (RBF)':       SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42),\n",
    "    'KNN (k=7)':       KNeighborsClassifier(n_neighbors=7, metric='euclidean'),\n",
    "    'Random Forest':   RandomForestClassifier(n_estimators=200, max_depth=12, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "print(f\"{'Model':<20} {'Accuracy':>10} {'Precision':>11} {'Recall':>9} {'F1':>8}\")\n",
    "print('-' * 60)\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    results[name] = {\n",
    "        'clf': clf, 'y_pred': y_pred,\n",
    "        'accuracy':  accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall':    recall_score(y_test, y_pred),\n",
    "        'f1':        f1_score(y_test, y_pred)\n",
    "    }\n",
    "    r = results[name]\n",
    "    print(f\"{name:<20} {r['accuracy']:>10.4f} {r['precision']:>11.4f} {r['recall']:>9.4f} {r['f1']:>8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Section 8: Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Normal', 'Stressed']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "cmaps = ['Blues', 'Oranges', 'Greens']\n",
    "for ax, (name, res), cmap in zip(axes, results.items(), cmaps):\n",
    "    cm = confusion_matrix(y_test, res['y_pred'])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(ax=ax, colorbar=False, cmap=cmap)\n",
    "    ax.set_title(\n",
    "        f'{name}\\nAcc: {res[\"accuracy\"]:.2%}  F1: {res[\"f1\"]:.2%}',\n",
    "        fontweight='bold', fontsize=11\n",
    "    )\n",
    "\n",
    "plt.suptitle('üéØ Confusion Matrices ‚Äî All Classifiers', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/plot_confusion_matrices.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "print('Confusion matrix plot saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model detailed report\n",
    "best_name = max(results, key=lambda k: results[k]['f1'])\n",
    "best_pred = results[best_name]['y_pred']\n",
    "print(f'Best Model: {best_name}\\n')\n",
    "print(classification_report(y_test, best_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üå≤ Section 9: Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = results['Random Forest']['clf']\n",
    "importances = rf.feature_importances_\n",
    "top_n = 15\n",
    "top_idx = np.argsort(importances)[::-1][:top_n]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.3, 0.9, top_n))\n",
    "ax.barh(\n",
    "    [feature_cols[i].replace('_', ' ') for i in top_idx[::-1]],\n",
    "    importances[top_idx[::-1]],\n",
    "    color=colors\n",
    ")\n",
    "ax.set_xlabel('Feature Importance (Gini)')\n",
    "ax.set_title(f'Top {top_n} Most Important Features ‚Äî Random Forest', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/plot_feature_importance.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Section 10: Summary\n",
    "\n",
    "| Step | Done |\n",
    "|------|------|\n",
    "| Signal preprocessing (framing, windowing, STFT) | ‚úî |\n",
    "| Waveform & spectrogram visualization | ‚úî |\n",
    "| MFCC (13 coefficients + deltas) extraction | ‚úî |\n",
    "| ZCR, Spectral Centroid, RMS Energy, Pitch | ‚úî |\n",
    "| MFCC trajectory + variance analysis | ‚úî |\n",
    "| Feature distribution comparison | ‚úî |\n",
    "| SVM / KNN / Random Forest classification | ‚úî |\n",
    "| Confusion matrix + classification report | ‚úî |\n",
    "| Feature importance analysis | ‚úî |\n",
    "\n",
    "---\n",
    "### üí° Key Findings\n",
    "- **Stressed speech** exhibits higher fundamental frequency (pitch), greater pitch jitter, and elevated spectral energy compared to normal speech.\n",
    "- **MFCC variance** is consistently higher in stressed samples, reflecting less stable phoneme articulation.\n",
    "- **Random Forest** typically achieves the best generalization due to ensemble averaging over noisy acoustic features.\n",
    "- **Top features:** pitch standard deviation, MFCC-1 mean, RMS energy, and spectral centroid are most discriminative.\n",
    "\n",
    "---\n",
    "*To use real data, set `USE_SYNTHETIC = False` and provide paths to your RAVDESS / EmoDB / IITKGP audio files.*"
   ]
  }
 ]
}
